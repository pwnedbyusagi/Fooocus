{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pwnedbyusagi/Fooocus/blob/main/Copy_of_fooocus_colab_import_any_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "0f8719f6-3998-4090-a398-8c238cc0d1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.12.2\n",
            "  Downloading pygit2-1.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pygit2==1.12.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.9.1->pygit2==1.12.2) (2.21)\n",
            "Installing collected packages: pygit2\n",
            "Successfully installed pygit2-1.12.2\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 4638, done.\u001b[K\n",
            "remote: Counting objects: 100% (1182/1182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (267/267), done.\u001b[K\n",
            "remote: Total 4638 (delta 960), reused 962 (delta 907), pack-reused 3456\u001b[K\n",
            "Receiving objects: 100% (4638/4638), 24.75 MiB | 5.87 MiB/s, done.\n",
            "Resolving deltas: 100% (2839/2839), done.\n",
            "/content/Fooocus\n"
          ]
        }
      ],
      "source": [
        "# Run first - we need to install the required dependencies and then clone the latest version of Fooocus\n",
        "!pip install pygit2==1.12.2\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install any additional Fooocus dependencies e.g. upscaler\n",
        "!wget -O /content/Fooocus/models/upscale_models/fooocus_upscaler_s409985e5.bin https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_upscaler_s409985e5.bin?download=true"
      ],
      "metadata": {
        "id": "jVA5oCVfDVgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model you want to run and save it to the checkpoint folder\n",
        "!wget -O /content/Fooocus/models/checkpoints/realism_engine_sdxl.safetensors https://civitai.com/api/download/models/258380?type=Model&format=SafeTensor&size=pruned&fp=fp16\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPXtSHIcUrT1",
        "outputId": "3b860b96-8e72-484b-c3fd-ad34b465f3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-13 22:25:30--  https://civitai.com/api/download/models/258380?type=Model\n",
            "Resolving civitai.com (civitai.com)... 104.18.22.206, 104.18.23.206, 2606:4700::6812:16ce, ...\n",
            "Connecting to civitai.com (civitai.com)|104.18.22.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/8215/realismenginesdxlV20.ZghE.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22realismEngineSDXL_v20VAE.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20231213/us-east-1/s3/aws4_request&X-Amz-Date=20231213T222531Z&X-Amz-SignedHeaders=host&X-Amz-Signature=6b2fc78201b7d408561a33b005cc39d327cc66bc0e00ba21629d86945676b152 [following]\n",
            "--2023-12-13 22:25:31--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/8215/realismenginesdxlV20.ZghE.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22realismEngineSDXL_v20VAE.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20231213/us-east-1/s3/aws4_request&X-Amz-Date=20231213T222531Z&X-Amz-SignedHeaders=host&X-Amz-Signature=6b2fc78201b7d408561a33b005cc39d327cc66bc0e00ba21629d86945676b152\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 104.18.8.90, 104.18.9.90, 2606:4700::6812:85a, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|104.18.8.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6939220250 (6.5G)\n",
            "Saving to: ‘/content/Fooocus/models/checkpoints/realism_engine_sdxl.safetensors’\n",
            "\n",
            "/content/Fooocus/mo 100%[===================>]   6.46G  64.4MB/s    in 96s     \n",
            "\n",
            "2023-12-13 22:27:07 (68.8 MB/s) - ‘/content/Fooocus/models/checkpoints/realism_engine_sdxl.safetensors’ saved [6939220250/6939220250]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Fooocus!\n",
        "!python entry_with_update.py --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQyPnqbFUsgS",
        "outputId": "b25ec702-1cbf-49f6-e6e2-9912c21c8044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share']\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Fooocus version: 2.1.837\n",
            "Installing requirements\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_version6Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:36<00:00, 197MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 204MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 11.5MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 10.9MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xl-to-v1_interposer-v3.1.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v3.1.safetensors\n",
            "\n",
            "100% 6.25M/6.25M [00:00<00:00, 111MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 256MB/s]\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "2023-12-13 22:29:02.815260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 22:29:02.815330: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 22:29:02.815375: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Running on public URL: https://695350ed45fccd031f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "2023-12-13 22:29:04.339996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://695350ed45fccd031f.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 360340048859314386\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['conditioner.embedders.0.logit_scale', 'conditioner.embedders.0.text_projection'])\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/realism_engine_sdxl.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/Fooocus/models/checkpoints/realism_engine_sdxl.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/realism_engine_sdxl.safetensors] with 788 keys at weight 0.1.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.31 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A brunette girl on the beach, windswept, taken on an iPhone, sharp focus, coherent, intricate, elegant, highly detailed, symmetry, warm light, thought, strong, cinematic, background, professional, designed, vivid colors, cool, dynamic, ambient, rich deep color, epic, grand composition, set, open, sunny, inspired, beautiful, amazing\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A brunette girl on the beach, windswept, taken on an iPhone, innocent, aesthetic, romantic, gorgeous, intricate, highly detailed, sharp focus, emotional, cute, enchanted, background, cinematic, complex, elegant, lush, thought, iconic, fine detail, full color, elaborate, very inspirational, vibrant, brilliant, colorful, surreal, epic, contemporary\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 49.09 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.40 seconds\n",
            "100% 30/30 [00:25<00:00,  1.18it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2023-12-13/log.html\n",
            "Generating and saving time: 30.67 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.87 seconds\n",
            "100% 30/30 [00:25<00:00,  1.18it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "Image generated with private log at: /content/Fooocus/outputs/2023-12-13/log.html\n",
            "Generating and saving time: 30.29 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.49 seconds\n",
            "Total time: 114.92 seconds\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2199, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/entry_with_update.py\", line 46, in <module>\n",
            "    from launch import *\n",
            "  File \"/content/Fooocus/launch.py\", line 109, in <module>\n",
            "    from webui import *\n",
            "  File \"/content/Fooocus/webui.py\", line 545, in <module>\n",
            "    shared.gradio_root.launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2115, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2203, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 49, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7865 <> https://695350ed45fccd031f.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}